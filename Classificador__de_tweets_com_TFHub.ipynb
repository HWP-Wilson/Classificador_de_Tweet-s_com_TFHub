{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Classificador _de_tweets_com_TFHub.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HWP-Wilson/Classificador_de_Tweet-s_com_TFHub/blob/main/Classificador__de_tweets_com_TFHub.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "feFbqZpP1soY"
      },
      "source": [
        "# Classificador de Tweet  com modelo  TF Hub\n",
        "@helanowilson@ufc.br\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOEllRxGQ_me",
        "outputId": "4c98becb-3b0b-444e-e5e5-583bb95d6683"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import json\n",
        "import pickle\n",
        "import urllib\n",
        "\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn import preprocessing\n",
        "\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
        "import wordninja\n",
        "import textblob\n",
        "import re\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvwN2Jkx2CdU"
      },
      "source": [
        "## Dataset\n",
        "\n",
        "Temos aproxidamente 25 mil tweets classificados em Discurso de ódio, linguagem ofensiva ou Neutro. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NaZiKWtGyoQE",
        "outputId": "55ff4a80-bb88-4273-8827-96e780b1fdfa"
      },
      "source": [
        "##Dataset\n",
        "data = pd.read_csv('Dados/labeled_data.csv')\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>count</th>\n",
              "      <th>hate_speech</th>\n",
              "      <th>offensive_language</th>\n",
              "      <th>neither</th>\n",
              "      <th>class</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
              "0           0      3            0                   0        3      2   \n",
              "1           1      3            0                   3        0      1   \n",
              "2           2      3            0                   3        0      1   \n",
              "3           3      3            0                   2        1      1   \n",
              "4           4      6            0                   6        0      1   \n",
              "\n",
              "                                               tweet  \n",
              "0  !!! RT @mayasolovely: As a woman you shouldn't...  \n",
              "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...  \n",
              "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...  \n",
              "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...  \n",
              "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBLcNSE_7Icv"
      },
      "source": [
        "## Ajustes nos dados para implementação do modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnnlJ16At8oU"
      },
      "source": [
        "##Criação de dicionário para classificação\n",
        "Classe = {0: ['Discurso de ódio'], 1: ['Linguagem ofensiva'], 2: ['Neutro']}\n",
        "data['classe']= data['class'].map(Classe)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZD5t5lpBt8oV"
      },
      "source": [
        "# Excluindo da descrição os números, informações julgadas irrelevantes para a classificação.\n",
        "data['tweet_novo'] = data['tweet'].str.replace('[0-9]+', '', regex=True).copy()\n",
        "# Excluindo da descrição puntuação, informações julgadas irrelevantes para a classificação.\n",
        "data['tweet_novo'] = data['tweet_novo'].str.replace('[,.:;!?]+', ' ', regex=True).copy()\n",
        "# Excluindo da descrição caracteres especiais, informações julgadas irrelevantes para a classificação.\n",
        "data['tweet_novo'] = data['tweet_novo'].str.replace(\"(@[A-Za-z0-9]+)|(#[A-Za-z0-9]+)\", \" \", regex=True).copy()\n",
        "\n",
        "# Colocando todos os caracteres em caixa baixa.\n",
        "data['tweet_novo'] = data['tweet_novo'].str.lower().copy()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MC9TAOjDt8oW",
        "outputId": "a100dd06-0c92-481e-a1fe-286bb5887199"
      },
      "source": [
        "# Função para retirar stop words\n",
        "punct = list(string.punctuation)\n",
        "stop_words = stopwords.words('english')\n",
        "additional_stop_words = ['RT', 'rt', 'via', '...', 'http', 'twitpic',\n",
        "'tinyurl' ,'www']\n",
        "stopword_list = punct + stop_words + additional_stop_words\n",
        "def tokenize_df(tokenized_words):\n",
        "  tokenized_words = word_tokenize(tokenized_words)\n",
        "  stop = [word for word in tokenized_words if word not in stopword_list]\n",
        "  text = TreebankWordDetokenizer().detokenize(stop)\n",
        "  return text\n",
        "# Eliminando as stop words\n",
        "data['tweet_organizado'] = data['tweet_novo'].apply(tokenize_df).copy()\n",
        "data.head(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>count</th>\n",
              "      <th>hate_speech</th>\n",
              "      <th>offensive_language</th>\n",
              "      <th>neither</th>\n",
              "      <th>class</th>\n",
              "      <th>tweet</th>\n",
              "      <th>classe</th>\n",
              "      <th>tweet_novo</th>\n",
              "      <th>tweet_organizado</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
              "      <td>[Neutro]</td>\n",
              "      <td>rt    as a woman you shouldn't complain abou...</td>\n",
              "      <td>womann't complain cleaning house amp man alway...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
              "      <td>[Linguagem ofensiva]</td>\n",
              "      <td>rt    boy dats cold tyga dwn bad for cuffin ...</td>\n",
              "      <td>boy dats cold tyga dwn bad cuffin dat hoe st p...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
              "0           0      3            0                   0        3      2   \n",
              "1           1      3            0                   3        0      1   \n",
              "\n",
              "                                               tweet                classe  \\\n",
              "0  !!! RT @mayasolovely: As a woman you shouldn't...              [Neutro]   \n",
              "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...  [Linguagem ofensiva]   \n",
              "\n",
              "                                          tweet_novo  \\\n",
              "0    rt    as a woman you shouldn't complain abou...   \n",
              "1    rt    boy dats cold tyga dwn bad for cuffin ...   \n",
              "\n",
              "                                    tweet_organizado  \n",
              "0  womann't complain cleaning house amp man alway...  \n",
              "1  boy dats cold tyga dwn bad cuffin dat hoe st p...  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "GINRHSbyt8oX",
        "outputId": "65f455f4-c0eb-45d0-9f91-172e2552f6e2"
      },
      "source": [
        "# Separando palavras juntas\n",
        "data['text_split'] = data['tweet_organizado'].apply(wordninja.split)\n",
        "data['text_novo'] = data['text_split'].apply(TreebankWordDetokenizer().detokenize)\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>count</th>\n",
              "      <th>hate_speech</th>\n",
              "      <th>offensive_language</th>\n",
              "      <th>neither</th>\n",
              "      <th>class</th>\n",
              "      <th>tweet</th>\n",
              "      <th>classe</th>\n",
              "      <th>tweet_novo</th>\n",
              "      <th>tweet_organizado</th>\n",
              "      <th>text_split</th>\n",
              "      <th>text_novo</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
              "      <td>[Neutro]</td>\n",
              "      <td>rt    as a woman you shouldn't complain abou...</td>\n",
              "      <td>womann't complain cleaning house amp man alway...</td>\n",
              "      <td>[woman, n, ', t, complain, cleaning, house, am...</td>\n",
              "      <td>woman n' t complain cleaning house amp man alw...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
              "      <td>[Linguagem ofensiva]</td>\n",
              "      <td>rt    boy dats cold tyga dwn bad for cuffin ...</td>\n",
              "      <td>boy dats cold tyga dwn bad cuffin dat hoe st p...</td>\n",
              "      <td>[boy, dat, s, cold, tyga, dw, n, bad, cuff, in...</td>\n",
              "      <td>boy dat s cold tyga dw n bad cuff in dat hoe s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
              "      <td>[Linguagem ofensiva]</td>\n",
              "      <td>rt   dawg  rt    you ever fuck a bitch and s...</td>\n",
              "      <td>dawg ever fuck bitch start cry confused shit</td>\n",
              "      <td>[daw, g, ever, fuck, bitch, start, cry, confus...</td>\n",
              "      <td>daw g ever fuck bitch start cry confused shit</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
              "      <td>[Linguagem ofensiva]</td>\n",
              "      <td>rt  _g_anderson   _based she look like a tranny</td>\n",
              "      <td>_g_anderson _based look like tranny</td>\n",
              "      <td>[g, anderson, based, look, like, tr, an, ny]</td>\n",
              "      <td>g anderson based look like tr an ny</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n",
              "      <td>[Linguagem ofensiva]</td>\n",
              "      <td>rt    the shit you hear about me might be tr...</td>\n",
              "      <td>shit hear might true might faker bitch told ya</td>\n",
              "      <td>[shit, hear, might, true, might, faker, bitch,...</td>\n",
              "      <td>shit hear might true might faker bitch told ya</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
              "0           0      3            0                   0        3      2   \n",
              "1           1      3            0                   3        0      1   \n",
              "2           2      3            0                   3        0      1   \n",
              "3           3      3            0                   2        1      1   \n",
              "4           4      6            0                   6        0      1   \n",
              "\n",
              "                                               tweet                classe  \\\n",
              "0  !!! RT @mayasolovely: As a woman you shouldn't...              [Neutro]   \n",
              "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...  [Linguagem ofensiva]   \n",
              "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...  [Linguagem ofensiva]   \n",
              "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...  [Linguagem ofensiva]   \n",
              "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...  [Linguagem ofensiva]   \n",
              "\n",
              "                                          tweet_novo  \\\n",
              "0    rt    as a woman you shouldn't complain abou...   \n",
              "1    rt    boy dats cold tyga dwn bad for cuffin ...   \n",
              "2    rt   dawg  rt    you ever fuck a bitch and s...   \n",
              "3    rt  _g_anderson   _based she look like a tranny   \n",
              "4    rt    the shit you hear about me might be tr...   \n",
              "\n",
              "                                    tweet_organizado  \\\n",
              "0  womann't complain cleaning house amp man alway...   \n",
              "1  boy dats cold tyga dwn bad cuffin dat hoe st p...   \n",
              "2       dawg ever fuck bitch start cry confused shit   \n",
              "3                _g_anderson _based look like tranny   \n",
              "4     shit hear might true might faker bitch told ya   \n",
              "\n",
              "                                          text_split  \\\n",
              "0  [woman, n, ', t, complain, cleaning, house, am...   \n",
              "1  [boy, dat, s, cold, tyga, dw, n, bad, cuff, in...   \n",
              "2  [daw, g, ever, fuck, bitch, start, cry, confus...   \n",
              "3       [g, anderson, based, look, like, tr, an, ny]   \n",
              "4  [shit, hear, might, true, might, faker, bitch,...   \n",
              "\n",
              "                                           text_novo  \n",
              "0  woman n' t complain cleaning house amp man alw...  \n",
              "1  boy dat s cold tyga dw n bad cuff in dat hoe s...  \n",
              "2      daw g ever fuck bitch start cry confused shit  \n",
              "3                g anderson based look like tr an ny  \n",
              "4     shit hear might true might faker bitch told ya  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "rplfxEAut8oY",
        "outputId": "0a076518-0f9f-4f12-d7bd-1a4ff10cd4de"
      },
      "source": [
        "#corrigindo palavras incorretas\n",
        "data['tweet_definitivo'] = data['text_novo'].apply(textblob.TextBlob).apply(textblob.TextBlob.correct).apply(str)\n",
        "data.head(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>count</th>\n",
              "      <th>hate_speech</th>\n",
              "      <th>offensive_language</th>\n",
              "      <th>neither</th>\n",
              "      <th>class</th>\n",
              "      <th>tweet</th>\n",
              "      <th>classe</th>\n",
              "      <th>tweet_novo</th>\n",
              "      <th>tweet_organizado</th>\n",
              "      <th>text_split</th>\n",
              "      <th>text_novo</th>\n",
              "      <th>tweet_definitivo</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
              "      <td>[Neutro]</td>\n",
              "      <td>rt    as a woman you shouldn't complain abou...</td>\n",
              "      <td>womann't complain cleaning house amp man alway...</td>\n",
              "      <td>[woman, n, ', t, complain, cleaning, house, am...</td>\n",
              "      <td>woman n' t complain cleaning house amp man alw...</td>\n",
              "      <td>woman n' t complain cleaning house amp man alw...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
              "      <td>[Linguagem ofensiva]</td>\n",
              "      <td>rt    boy dats cold tyga dwn bad for cuffin ...</td>\n",
              "      <td>boy dats cold tyga dwn bad cuffin dat hoe st p...</td>\n",
              "      <td>[boy, dat, s, cold, tyga, dw, n, bad, cuff, in...</td>\n",
              "      <td>boy dat s cold tyga dw n bad cuff in dat hoe s...</td>\n",
              "      <td>boy dat s cold tea do n bad cuff in dat he st ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
              "0           0      3            0                   0        3      2   \n",
              "1           1      3            0                   3        0      1   \n",
              "\n",
              "                                               tweet                classe  \\\n",
              "0  !!! RT @mayasolovely: As a woman you shouldn't...              [Neutro]   \n",
              "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...  [Linguagem ofensiva]   \n",
              "\n",
              "                                          tweet_novo  \\\n",
              "0    rt    as a woman you shouldn't complain abou...   \n",
              "1    rt    boy dats cold tyga dwn bad for cuffin ...   \n",
              "\n",
              "                                    tweet_organizado  \\\n",
              "0  womann't complain cleaning house amp man alway...   \n",
              "1  boy dats cold tyga dwn bad cuffin dat hoe st p...   \n",
              "\n",
              "                                          text_split  \\\n",
              "0  [woman, n, ', t, complain, cleaning, house, am...   \n",
              "1  [boy, dat, s, cold, tyga, dw, n, bad, cuff, in...   \n",
              "\n",
              "                                           text_novo  \\\n",
              "0  woman n' t complain cleaning house amp man alw...   \n",
              "1  boy dat s cold tyga dw n bad cuff in dat hoe s...   \n",
              "\n",
              "                                    tweet_definitivo  \n",
              "0  woman n' t complain cleaning house amp man alw...  \n",
              "1  boy dat s cold tea do n bad cuff in dat he st ...  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3MJhzkzWt8oZ"
      },
      "source": [
        "descriptions = data['tweet_definitivo']\n",
        "genres =data['classe']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUMgl8uLt8oZ",
        "outputId": "b766b668-37e3-4986-afcf-6c3c84f521c2"
      },
      "source": [
        "classification=genres.to_numpy()\n",
        "classification"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([list(['Neutro']), list(['Linguagem ofensiva']),\n",
              "       list(['Linguagem ofensiva']), ..., list(['Linguagem ofensiva']),\n",
              "       list(['Linguagem ofensiva']), list(['Neutro'])], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nticMcj1alW"
      },
      "source": [
        "train_size = int(len(descriptions) * .8)\n",
        "\n",
        "train_descriptions = descriptions[:train_size].astype('str')\n",
        "train_genres = genres[:train_size]\n",
        "\n",
        "test_descriptions = descriptions[train_size:].astype('str')\n",
        "test_genres = genres[train_size:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lOfooAtNt8ob",
        "outputId": "c7a0242c-aea0-4e56-aab5-3d83c133233a"
      },
      "source": [
        "test_genres.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19826                [Neutro]\n",
              "19827    [Linguagem ofensiva]\n",
              "19828    [Linguagem ofensiva]\n",
              "19829    [Linguagem ofensiva]\n",
              "19830                [Neutro]\n",
              "Name: classe, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FmZ9iqK88nSD"
      },
      "source": [
        "### Formatação das Labels, criando vetores. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xH85_vNRt8od",
        "outputId": "690f82e7-7eaa-407d-efa0-71b49e3f4170"
      },
      "source": [
        "encoder = MultiLabelBinarizer()\n",
        "encoder.fit_transform(train_genres)\n",
        "train_encoded = encoder.transform(train_genres)\n",
        "test_encoded = encoder.transform(test_genres)\n",
        "num_classes = len(encoder.classes_)\n",
        "\n",
        "# Printando as possibilidades de classifacação para cada tweet e para o primeiro tweet.\n",
        "print(encoder.classes_)\n",
        "print(train_encoded[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Discurso de ódio' 'Linguagem ofensiva' 'Neutro']\n",
            "[0 0 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ir8ez0K_9sYA"
      },
      "source": [
        "### Criando TF Hub embedding layer\n",
        "Vetorização de todo o texto na coluna descrição. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWuNUXq7a-7p"
      },
      "source": [
        "description_embeddings = hub.text_embedding_column(\"descriptions\", module_spec=\"https://tfhub.dev/google/universal-sentence-encoder/2\", trainable=False)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vscf4Fo-iI-"
      },
      "source": [
        "## Instanciando o modelo com DNNEstimator \n",
        "O primeiro parâmetro que passamos para nosso DNNEstimator é chamado de cabeça e define o tipo de rótulos que nosso modelo deve esperar. Como queremos que nosso modelo produza vários rótulos, usaremos multi_label_head aqui. Em seguida, converteremos nossos recursos e rótulos em matrizes numpy e instanciaremos nosso Estimator. `batch_size` e` num_epochs` são hiperparâmetros  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0Vsmu9O21je"
      },
      "source": [
        "multi_label_head = tf.estimator.MultiLabelHead(\n",
        "    num_classes, weight_column=None, thresholds=None, label_vocabulary=None,\n",
        "    loss_reduction=tf.losses.Reduction.SUM_OVER_BATCH_SIZE\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "8mTpWD_Q8GKe",
        "outputId": "582ae6df-a62d-4cfc-a558-3a901435875f"
      },
      "source": [
        "features = {\n",
        "  \"descriptions\": np.array(train_descriptions).astype(np.str)\n",
        "}\n",
        "labels = np.array(train_encoded).astype(np.int32)\n",
        "train_input_fn = tf.compat.v1.estimator.inputs.numpy_input_fn(features, labels, shuffle=True, batch_size=1024, num_epochs=25)\n",
        "estimator = tf.estimator.DNNEstimator(\n",
        "    head=multi_label_head,\n",
        "    hidden_units=[64,10],\n",
        "    feature_columns=[description_embeddings])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using default config.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using default config.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\Jamili\\AppData\\Local\\Temp\\tmpnxd7fuzz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\Jamili\\AppData\\Local\\Temp\\tmpnxd7fuzz\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\Jamili\\\\AppData\\\\Local\\\\Temp\\\\tmpnxd7fuzz', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\Jamili\\\\AppData\\\\Local\\\\Temp\\\\tmpnxd7fuzz', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ak1cZPZ_ZYM"
      },
      "source": [
        "## Treinando e executando o modelo\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "jmtvJ5o3Olcg",
        "outputId": "2be2af63-b27a-4dae-fcb7-57829949ef98"
      },
      "source": [
        "estimator.train(input_fn=train_input_fn)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From C:\\Users\\Jamili\\.conda\\lib\\site-packages\\tensorflow\\python\\training\\training_util.py:235: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From C:\\Users\\Jamili\\.conda\\lib\\site-packages\\tensorflow\\python\\training\\training_util.py:235: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From C:\\Users\\Jamili\\.conda\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\inputs\\queues\\feeding_queue_runner.py:60: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From C:\\Users\\Jamili\\.conda\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\inputs\\queues\\feeding_queue_runner.py:60: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From C:\\Users\\Jamili\\.conda\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\inputs\\queues\\feeding_functions.py:491: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From C:\\Users\\Jamili\\.conda\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\inputs\\queues\\feeding_functions.py:491: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From C:\\Users\\Jamili\\.conda\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\adagrad.py:82: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From C:\\Users\\Jamili\\.conda\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\adagrad.py:82: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Create CheckpointSaverHook.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Create CheckpointSaverHook.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From C:\\Users\\Jamili\\.conda\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py:906: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From C:\\Users\\Jamili\\.conda\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py:906: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 0 into C:\\Users\\Jamili\\AppData\\Local\\Temp\\tmpnxd7fuzz\\model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 0 into C:\\Users\\Jamili\\AppData\\Local\\Temp\\tmpnxd7fuzz\\model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.68011355, step = 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.68011355, step = 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 4.68067\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 4.68067\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.6661433, step = 100 (21.358 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.6661433, step = 100 (21.358 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 5.33276\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 5.33276\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.64848936, step = 200 (18.680 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.64848936, step = 200 (18.680 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 5.34125\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 5.34125\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.6266004, step = 300 (18.738 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.6266004, step = 300 (18.738 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 5.3697\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 5.3697\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.62016654, step = 400 (18.626 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.62016654, step = 400 (18.626 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 485...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 485...\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 485 into C:\\Users\\Jamili\\AppData\\Local\\Temp\\tmpnxd7fuzz\\model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 485 into C:\\Users\\Jamili\\AppData\\Local\\Temp\\tmpnxd7fuzz\\model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 485...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 485...\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Loss for final step: 0.604857.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Loss for final step: 0.604857.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow_estimator.python.estimator.canned.dnn.DNNEstimatorV2 at 0x5191997a30>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMgti0YmJO7F",
        "outputId": "d727b698-bc56-4100-e7aa-f66df6bc104d"
      },
      "source": [
        "# Definindo as entradas e avaliador\n",
        "eval_input_fn = tf.compat.v1.estimator.inputs.numpy_input_fn({\"descriptions\": np.array(test_descriptions).astype(np.str)}, test_encoded.astype(np.int32), shuffle=False)\n",
        "estimator.evaluate(input_fn=eval_input_fn)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Starting evaluation at 2021-03-23T16:57:18Z\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Starting evaluation at 2021-03-23T16:57:18Z\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from C:\\Users\\Jamili\\AppData\\Local\\Temp\\tmpnxd7fuzz\\model.ckpt-485\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from C:\\Users\\Jamili\\AppData\\Local\\Temp\\tmpnxd7fuzz\\model.ckpt-485\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Inference Time : 109.13508s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Inference Time : 109.13508s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished evaluation at 2021-03-23-16:59:07\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished evaluation at 2021-03-23-16:59:07\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving dict for global step 485: auc = 0.8805411, auc_precision_recall = 0.7594211, average_loss = 0.60455483, global_step = 485, loss = 0.60451764\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving dict for global step 485: auc = 0.8805411, auc_precision_recall = 0.7594211, average_loss = 0.60455483, global_step = 485, loss = 0.60451764\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 485: C:\\Users\\Jamili\\AppData\\Local\\Temp\\tmpnxd7fuzz\\model.ckpt-485\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 485: C:\\Users\\Jamili\\AppData\\Local\\Temp\\tmpnxd7fuzz\\model.ckpt-485\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'auc': 0.8805411,\n",
              " 'auc_precision_recall': 0.7594211,\n",
              " 'average_loss': 0.60455483,\n",
              " 'loss': 0.60451764,\n",
              " 'global_step': 485}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mcPyCfmWABVO"
      },
      "source": [
        "## Predições com novos dados\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixlCKF6NEkTx"
      },
      "source": [
        "# Testando o modelo com dados já existentes\n",
        "raw_test = [\n",
        "    \"As a woman you shouldnt complain about cleaning up your house amp as a man you should always take the trash out.\", # Neutro\n",
        "    \"bitch nigga miss me with it.\", # Linguagem ofensiva\n",
        "    \"playing football with friends.\", # Neutro\n",
        "]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHpMIWFsE4OB"
      },
      "source": [
        "# Gerando predições\n",
        "predict_input_fn = tf.compat.v1.estimator.inputs.numpy_input_fn({\"descriptions\": np.array(raw_test).astype(np.str)}, shuffle=False)\n",
        "results = estimator.predict(predict_input_fn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMVzrHpPDvoy",
        "outputId": "e6406d34-661a-4832-adcd-4a88ce94bd72"
      },
      "source": [
        "# Mostrando as predições\n",
        "for tweet_genres in results:\n",
        "  top_2 = tweet_genres['probabilities'].argsort()[-2:][::-1]\n",
        "  for genre in top_2:\n",
        "    text_genre = encoder.classes_[genre]\n",
        "    print(text_genre + ': ' + str(round(tweet_genres['probabilities'][genre] * 100, 2)) + '%')\n",
        "  print('')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from C:\\Users\\Jamili\\AppData\\Local\\Temp\\tmpnxd7fuzz\\model.ckpt-485\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from C:\\Users\\Jamili\\AppData\\Local\\Temp\\tmpnxd7fuzz\\model.ckpt-485\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Linguagem ofensiva: 54.28%\n",
            "Neutro: 46.6%\n",
            "\n",
            "Linguagem ofensiva: 55.29%\n",
            "Neutro: 46.72%\n",
            "\n",
            "Linguagem ofensiva: 54.48%\n",
            "Neutro: 47.66%\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CfZTfK-e7MJr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}